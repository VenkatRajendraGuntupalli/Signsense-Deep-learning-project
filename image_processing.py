# -*- coding: utf-8 -*-
"""image_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bEq7rRqKqn9Ru8aGxGUQYzPnn0AKcLU-
"""

!pip install imgaug

from google.colab import drive
drive.mount('/content/drive')

import os

print('Left Curve',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Left Curve')))
print('Loose Gravel',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Loose Gravel')))
print('Pot Holes',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Pot Holes')))
print('Right Curve',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Right Curve')))
print('S Curved',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/S Curved')))
print('Snow Covered',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Snow Covered')))
print('Straight Roads',len(os.listdir('/content/drive/MyDrive/Rajendra/Road Images/Straight Roads')))

import imgaug as ia
import imgaug
from imgaug import augmenters as iaa
import numpy as np
import imageio
import matplotlib.pyplot as plt
import glob
import os
import cv2
from tqdm import tqdm
ia.seed(1)
import random
# path="images/signature/pdf_images/preprocess/sample/"


# save_path='images/signature/pdf_images/preprocess/'

# files = os.listdir(path)
all_files = []
path = '/content/drive/MyDrive/Rajendra/Road Images/Right Curve/'
save_path = '/content/drive/MyDrive/Rajendra/Road Images/Right Curve/'

name = 'CLAHE'

# if not os.path.exists(save_path):
#     os.makedirs(save_path)

for (dirpath, dirnames, files) in os.walk(path):
    all_files += [os.path.join(dirpath, file) for file in files]

for file in tqdm(random.sample(all_files,70), position=0, leave=True):
      # print(file)
    try:
      img = imageio.imread(file) #read you image
      #img = np.resize(img, (224, 224, 3))
      images = np.array(
      [img for _ in range(1)], dtype=np.uint8)  # 32 means create 32 enhanced images using following methods.
      #print(images.shape)


      seq = iaa.Sequential(
        [
          # iaa.AdditiveLaplaceNoise(scale=0.2*255),
          # iaa.Multiply((0.5, 2.5)),
          # iaa.SigmoidContrast(gain=(5, 5), cutoff=(0.4, 0.6), per_channel=True),
          # iaa.AllChannelsCLAHE(clip_limit=(1, 10), per_channel=True),
          iaa.CLAHE(tile_grid_size_px=((3, 21), [3, 5, 7])),

          # iaa.Dropout2d(p=0.8),
          # iaa.imgcorruptlike.Fog(severity=2),
          # iaa.imgcorruptlike.Brightness(severity=2),
          ##iaa.pillike.Autocontrast((10, 20), per_channel=True),
        ],random_order=True)  # apply augmenters in random order

      images_aug = seq.augment_images(images)
      for i in range(1):
          # print(i)
          # plt.imshow(images_aug[i])
          # plt.show()
          #print(save_path+str(i)+'_'+fname)  #write all changed images

          #new_image_path = ('%s/%s_Additivelaplacenoise_augmented_%s'%(save_path,i,os.path.basename(file)))
          #new_image_path = ('%s/%s_multiply_augmented_%s'%(save_path,i,os.path.basename(file)))
          # new_image_path = ('%s/%s_SigmoidContrast_augmented_%s'%(save_path,i,os.path.basename(file)))
          #new_image_path = ('%s/%s_AllChannelsCLAHE_augmented_%s'%(save_path,i,os.path.basename(file)))
          new_image_path = ('%s/%s_%s_augmented1_%s'%(save_path,i,name,os.path.basename(file)))

          #print(new_image_path)
          imageio.imwrite(new_image_path, images_aug[i])  #write all changed images
    except:
        print(file)
    #     #cv2.imwrite(new_image_path, images_aug[i])
      # break





"""### Training"""

import tensorflow as tf
import random
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
# Set the path to the dataset directory
dataset_path = "/content/drive/MyDrive/Rajendra/Road Images"

# Set the image dimensions and batch size
img_height, img_width = 150, 150
batch_size = 32

# Data preprocessing and augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    validation_split=0.1
)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Build and train the CNN model
model_cnn = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(6, activation='softmax')
])

model_cnn.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

history = model_cnn.fit(train_generator, validation_data=validation_generator,epochs=10)

# Get the training and validation accuracy values from the history object
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

# Plot the training and validation accuracy curves
epochs = range(1, len(train_accuracy) + 1)

plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')
plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')

plt.title('Training and Validation Accuracy for CNN')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Apply transfer learning using pre-trained model
base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height, img_width, 3),
                                               include_top=False,
                                               weights='imagenet')

base_model.trainable = False

model_transfer_learning = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dense(6, activation='softmax')
])

model_transfer_learning.compile(optimizer='adam',
                                loss='categorical_crossentropy',
                                metrics=['accuracy'])

history_tf = model_transfer_learning.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=10
)

# Get the training and validation accuracy values from the history object
train_accuracy = history_tf.history['accuracy']
val_accuracy = history_tf.history['val_accuracy']

# Plot the training and validation accuracy curves
epochs = range(1, len(train_accuracy) + 1)

plt.plot(epochs, train_accuracy, 'b', label='Training Accuracy')
plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')

plt.title('Training and Validation Accuracy for Transfer Learning')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Saving the trained model
model_transfer_learning.save('/content/drive/MyDrive/Rajendra/models/trained_model.h5')
model_cnn.save('/content/drive/MyDrive/Rajendra/models/cnn_trained_model.h5')

# Evaluate the models
cnn_loss, cnn_accuracy = model_cnn.evaluate(validation_generator)
transfer_loss, transfer_accuracy = model_transfer_learning.evaluate(validation_generator)

print("CNN Model - Loss:", cnn_loss, "Accuracy:", cnn_accuracy)
print("Transfer Learning Model - Loss:", transfer_loss, "Accuracy:", transfer_accuracy)

import numpy as np
from tensorflow.keras.preprocessing import image

# Load and preprocess the test image
test_image_path = "/content/drive/MyDrive/Rajendra/testing/s_curve1.jpg"
test_image = image.load_img(test_image_path, target_size=(img_height, img_width))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis=0)
test_image /= 255.0

# Make predictions using the CNN model
cnn_predictions = model_cnn.predict(test_image)
cnn_predicted_class = np.argmax(cnn_predictions)
cnn_class_labels = train_generator.class_indices
cnn_predicted_label = list(cnn_class_labels.keys())[list(cnn_class_labels.values()).index(cnn_predicted_class)]

# Make predictions using the transfer learning model
transfer_predictions = model_transfer_learning.predict(test_image)
transfer_predicted_class = np.argmax(transfer_predictions)
transfer_class_labels = train_generator.class_indices
transfer_predicted_label = list(transfer_class_labels.keys())[list(transfer_class_labels.values()).index(transfer_predicted_class)]

# Print the predictions
print("CNN Predicted Label:", cnn_predicted_label)
print("Transfer Learning Predicted Label:", transfer_predicted_label)

import numpy as np
from tensorflow.keras.preprocessing import image


# Loading the saved model
loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Rajendra/models/trained_model.h5')
# cnn_loaded_model = tf.keras.models.load_model('cnn_trained_model.h5')



def get_sign(img_path):
    # Load and preprocess the test image
    test_image_path = img_path
    test_image = image.load_img(test_image_path, target_size=(img_height, img_width))
    test_image = image.img_to_array(test_image)
    test_image = np.expand_dims(test_image, axis=0)
    test_image /= 255.0
    # Make predictions using the CNN model
#     cnn_predictions = cnn_loaded_model.predict(test_image)
#     cnn_predicted_class = np.argmax(cnn_predictions)
#     cnn_class_labels = train_generator.class_indices
#     cnn_predicted_label = list(cnn_class_labels.keys())[list(cnn_class_labels.values()).index(cnn_predicted_class)]

    # Make predictions using the transfer learning model
    transfer_predictions = loaded_model.predict(test_image)
    transfer_predicted_class = np.argmax(transfer_predictions)
    transfer_class_labels = train_generator.class_indices
    transfer_predicted_label = list(transfer_class_labels.keys())[list(transfer_class_labels.values()).index(transfer_predicted_class)]

    return transfer_predicted_label

image_mapping = {
  'Left Curve':'LeftCurve.jpg',
 'S Curved':'SCurve.jpg',
 'Snow Covered':'IceCovered_Road.png',
 'Pot Holes':'Potholes.jpg',
 'Right Curve':'RightCurve.jpg',
 'Straight Roads':'StraightRoad_SpeedSign.jpg'}

# from PIL import Image
# import matplotlib.pyplot as plt
# img_path = '/content/drive/MyDrive/Rajendra/testing/s_curve1.jpg'
# test_image = Image.open(img_path)

# transfer_predicted_label = get_sign(img_path)

# plt.imshow(test_image)
# plt.axis('off')
# plt.show()

# sign_name = os.path.join('/content/drive/MyDrive/Rajendra/signs',image_mapping[transfer_predicted_label])
# plt.imshow(Image.open(sign_name))
# plt.axis('off')
# plt.show()

os.listdir('/content/drive/MyDrive/Rajendra/Road Images')

os.listdir('/content/drive/MyDrive/Rajendra/signs')

from PIL import Image
import matplotlib.pyplot as plt
import os

def display_side_by_side_images(image_path, sign_path):
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))

    # Load and display the original image
    test_image = Image.open(image_path)
    axs[0].imshow(test_image)
    axs[0].axis('off')

    # Load and display the sign image
    sign_image = Image.open(sign_path)
    axs[1].imshow(sign_image)
    axs[1].axis('off')

    plt.show()

# Example usage:
img_path = '/content/drive/MyDrive/Rajendra/testing/stright2.jpg'
transfer_predicted_label = get_sign(img_path)
print(transfer_predicted_label)
sign_name = os.path.join('/content/drive/MyDrive/Rajendra/signs', image_mapping[transfer_predicted_label])
display_side_by_side_images(img_path, sign_name)

from PIL import Image
import matplotlib.pyplot as plt
import os

def display_side_by_side_images(image_path, sign_path, predicted_label):
    fig, axs = plt.subplots(1, 2, figsize=(10, 5))

    # Load and display the original image
    test_image = Image.open(image_path)
    axs[0].imshow(test_image)
    axs[0].axis('off')
    axs[0].set_title(f"Original Image")

    # Add predicted label to the image
    axs[0].text(10, 10, predicted_label, fontsize=12, color='red', bbox=dict(facecolor='white', alpha=0.8))

    # Load and display the sign image
    sign_image = Image.open(sign_path)
    axs[1].imshow(sign_image)
    axs[1].axis('off')
    axs[1].set_title(f"Sign Image")

    plt.show()

# Example usage:
img_path = '/content/drive/MyDrive/Rajendra/testing/strightroad1.JPG'
transfer_predicted_label = get_sign(img_path)
sign_name = os.path.join('/content/drive/MyDrive/Rajendra/signs', image_mapping[transfer_predicted_label])
display_side_by_side_images(img_path, sign_name, transfer_predicted_label)

